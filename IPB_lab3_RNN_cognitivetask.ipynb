{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Training RNNs on cognitive tasks"
      ],
      "metadata": {
        "id": "bH8uH8rx6MTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "\n",
        "##Quick Recap:\n",
        "In our last session, we delved into the dynamic world of Recurrent Neural Networks (RNNs). We explored their architecture and dynamics, witnessed the forward pass, and visualized the temporal dynamics unfolded through time. RNNs, with their looping mechanism, showcased a remarkable potential for handling sequential data, opening doors to a myriad of applications across various domains, including natural language processing, speech recognition, and indeed, neuroscience.\n",
        "\n",
        "##Objective:\n",
        "Today, we transition from understanding the mechanics of RNNs to deploying them effectively on cognitive tasks. We’ll explore how these networks, inspired by the recurrent connections in our brain, can be trained to perform tasks that mimic cognitive functions. Engaging in such exercises not only offers insights into artificial intelligence but also sheds light on the computational capabilities of our own neural circuits.\n",
        "\n",
        "Training neural networks involves tuning their parameters so that they can perform a specific task effectively, guided by a loss function that quantifies the error in their predictions. For RNNs, this encompasses adjusting weights in a temporal context, linking past, present, and future in a coherent, task-optimized manner.\n"
      ],
      "metadata": {
        "id": "qtd39htCstwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Glimpse into Modern RNN Architectures: LSTMs and GRUs\n",
        "\n",
        "Welcome to a brief sidebar in our learning journey, where we explore the lush landscapes of modern recurrent neural network architectures. Before we dive deep into training RNNs on cognitive tasks, let's acquaint ourselves with some advanced members of the RNN family: Long Short-Term Memory (LSTM) units and Gated Recurrent Units (GRU).\n",
        "\n",
        "### LSTMs: Bridging the Temporal Gap\n",
        "\n",
        "- **Problem Addressed**: RNNs, although potent in theory, often struggle with learning long-term dependencies due to vanishing and exploding gradient problems.\n",
        "  \n",
        "- **Solution Offered**: LSTMs introduce a **memory cell**, which, managed by various gates (input, forget, and output), enables them to store and retrieve information over longer sequences, thereby mitigating the issue of vanishing gradients to an extent.\n",
        "  \n",
        "### GRUs: Simplifying the Memory\n",
        "\n",
        "- **Motivation**: LSTMs, while powerful, come with a computational cost due to their complex structure.\n",
        "\n",
        "- **The GRU Twist**: GRUs modify the LSTM architecture, combining the functionality of some gates and offering a simpler model that still manages to retain information over time effectively.\n",
        "\n",
        "### Emerging RNN Variants: An Ongoing Exploration\n",
        "\n",
        "Both LSTMs and GRUs have led to significant advancements in dealing with sequential data, giving rise to variants and hybrids that aim to combine their benefits and navigate around their limitations. Some models experiment with peephole connections, bidirectional flows, and attention mechanisms, continually expanding the horizons of what RNNs can achieve.\n",
        "\n",
        "### Delving Deeper? Not Today!\n",
        "\n",
        "While the exciting adventures of LSTMs, GRUs, and their descendants beckon, today, our journey will keep its course focused on the fundamental aspects of training traditional RNNs, especially in the realm of cognitive tasks. This sidestep into the world of advanced RNN architectures aims to provide a map for future explorations, where your curiosity can guide you through intricate architectures and innovative applications.\n",
        "\n",
        "### For the Keen Explorers Among You\n",
        "\n",
        "Should your intrigue lead you to explore further into the deep forests of LSTMs, GRUs, and beyond, here are some links to guide your journey:\n",
        "\n",
        "- [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "- [Illustrated Guide to LSTM’s and GRU’s](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)\n",
        "- [RNNs and LSTMs](https://web.stanford.edu/~jurafsky/slp3/9.pdf)\n",
        "- [Vanishing & Exploding Gradient Problems](http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L15%20Exploding%20and%20Vanishing%20Gradients.pdf)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kiVHgfaFypi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leaky RNNs vs. RNNs in AI Models\n",
        "\n",
        "### Leaky RNNs\n",
        "- **Leakiness**: Leaky RNNs introduce a \"leak\" term, controlling how swiftly they forget previous states, maintaining a decaying memory of past inputs.\n",
        "- **Use-cases**: Beneficial in scenarios where a lingering memory of past inputs is useful, and in computational neuroscience to mimic certain biophysical properties of neurons.\n",
        "- **Equation**:\n",
        "\n",
        "\\begin{align}\n",
        "x(t) = \\alpha x(t-1) + (1 - \\alpha) \\phi(W x(t-1) + U u(t) + b)\n",
        "\\end{align}\n",
        "\n",
        "### Traditional RNNs\n",
        "- **Instant Update**: Traditional RNNs modify their hidden states entirely at each time step, directly influenced by the present input and prior state, without a leaky term.\n",
        "- **Use-cases**: In AI, traditional RNNs capture temporal dynamics without a decay term and find applications in NLP, time-series prediction, etc.\n",
        "- **Equation**:\n",
        "\n",
        "\\begin{align}\n",
        "x(t) = \\phi(W x(t-1) + U u(t) + b)\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "### Comparative Insight\n",
        "- **Memory**: Leaky RNNs have a form of fading memory due to the leaky term, whereas traditional RNNs have more transient memories of the past, potentially struggling with long-term dependencies without modifications (like using LSTMs or GRUs).\n",
        "- **Training Stability**: Leaky RNNs might offer enhanced stability during training since the linear leaky term can facilitate gradient flow during backpropagation through time, somewhat alleviating the vanishing gradient problem.\n",
        "\n",
        "### Further Reading\n",
        "1. **Vanishing & Exploding Gradients**: Explore these fundamental challenges in RNNs and how architectures like LSTMs and GRUs address them. [Read More](https://www.deeplearningbook.org/contents/rnn.html)\n",
        "2. **Applications of RNNs**: Dive into various applications of RNNs across domains from finance to healthcare. [Read More](https://arxiv.org/abs/1506.00019)\n",
        "\n"
      ],
      "metadata": {
        "id": "JUvJhD7TpWrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Navigating Back to Today's objective\n",
        "\n",
        "While the above-mentioned architectures and their variants are crucial in the broader context of deep learning, our primary focus today will not be on these models. With this brief glimpse into what lies beyond in the world of RNNs, let’s navigate back to our chosen path - training RNNs on cognitive tasks. We shall immerse ourselves in understanding how even the simple architectures that we learned in the previous tutorial can be potent tools to unravel and mimic cognitive processes. This focus ensures a solid foundation, enabling you to later explore more advanced architectures with a robust base of understanding.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZKlIz2Q7tKEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A quick side note:\n",
        "\n",
        "The primary objective of employing Recurrent Neural Networks (RNNs) in our context is not to precisely emulate learning processes in the brain, but rather to develop a tentative model suitable for various cognitive tasks of interest. Here are some reasons behind this approach:\n",
        "\n",
        "1. **Comprehensive Involvement of Brain Areas**: Cognition is a multifaceted function involving various brain regions, both cortical and subcortical, which is significantly more complex than a singular recurrent network.\n",
        "\n",
        "2. **Flexibility in Cognition vs. RNNs**: Unlike RNNs, which are typically trained for a specific task and hence lack flexibility, natural cognition is incredibly adaptable, enabling entities to manage a multitude of tasks and adapt to new ones.\n",
        "\n",
        "3. **Complexity and High-dimensional Input**: Animals experience a level of complexity far beyond that which can be replicated by an RNN. They receive and process high-dimensional inputs from their surroundings, illustrating a depth of interaction and processing that RNNs have not yet achieved.\n",
        "\n",
        "Considering these aspects, RNNs serve as a preliminary step towards computationally modeling cognitive processes. Although they don’t fully encapsulate the richness and complexity of cognitive functioning in living organisms, they offer a starting point from which we can explore, understand, and perhaps eventually simulate cognitive processes more accurately and effectively in computational models.\n",
        "\n"
      ],
      "metadata": {
        "id": "I9wz0XkPwkM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's proceed with our main topic for today - training RNNs on cognitive tasks!"
      ],
      "metadata": {
        "id": "jzU7LCTOKwof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a closer look at how this cognitive task is performed in real life to deepen our understanding. Here is a [link](https://www.youtube.com/watch?v=oDxcyTn-0os&ab_channel=PamelaReinagelatUCSD) to a video featuring a rat executing a task. Observing this can provide us with valuable insights and inspire our approach to developing computational models that emulate such cognitive processes. Enjoy watching, and let’s bring those observations into our tutorial today!\n",
        "\n"
      ],
      "metadata": {
        "id": "PvJC_XTZ2ogE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNsCB508r3UZ"
      },
      "source": [
        "### Installing and importing relevant packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drHbsMbKr3Ua"
      },
      "outputs": [],
      "source": [
        "# Install neurogym to use cognitive tasks\n",
        "! git clone https://github.com/neurogym/neurogym.git\n",
        "%cd neurogym/\n",
        "! pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYIY5KJtr3Ua"
      },
      "outputs": [],
      "source": [
        "# Import common packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjpUvzGNr3Ua"
      },
      "source": [
        "## Defining a recurrent neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "incorporated-editor"
      },
      "source": [
        "In general, recurrent neural networks transform **sequence to sequence**. In the context of cognitive neuroscience, the sequence is usually a time series of task input or output. Recall the sequence we produced in Tutorial 1 by executing a forward pass through an RNN?\n",
        "\n",
        "Let's understand the input and output dimensions of a typical recurrent network in machine learning, LSTM networks.\n",
        "\n",
        "(Usage example adopted from pytorch documentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VGmZ7mtr3Ub"
      },
      "outputs": [],
      "source": [
        "# Make a LSTM, input_size is the dimension of inputs,\n",
        "# hidden_size is the number of hidden neurons\n",
        "rnn = nn.LSTM(input_size=10, hidden_size=20, num_layers=2)\n",
        "\n",
        "# Generate some mock inputs\n",
        "input = torch.randn(5, 3, 10)  # The arguments represent (Sequence Length, Batch Size, Input Size). Typically, in neuroscience,\n",
        "# sequence length would correspond to time points in the time series, Batch size corresponds to the number of trials and\n",
        "# input size corresponds to the dimension of the input (ie., the number of neurons or channels you're collecting data from)\n",
        "output, (hn, cn) = rnn(input)\n",
        "\n",
        "print('Output shape is (SeqLen, BatchSize, HiddenSize):', output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "becoming-cement"
      },
      "outputs": [],
      "source": [
        "input = torch.randn(5, 3, 10)  # (Sequence Length, Batch Size, Input Size)\n",
        "\n",
        "lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=2)\n",
        "output, _ = lstm(input)\n",
        "print('Output shape is (SeqLen, BatchSize, Dimension):', output.shape)\n",
        "\n",
        "rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=2)\n",
        "output, _ = rnn(input)\n",
        "print('Output shape is (SeqLen, BatchSize, Dimension):', output.shape)\n",
        "\n",
        "gru = nn.GRU(input_size=10, hidden_size=20, num_layers=2)\n",
        "output, _ = gru(input)\n",
        "print('Output shape is (SeqLen, BatchSize, Dimension):', output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Defining a Continuous-Time Recurrent Neural Networks (CTRNNs)**"
      ],
      "metadata": {
        "id": "xg9fY5C4_snE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "proper-armor"
      },
      "source": [
        "Neuroscientists often prefer **Continuous-Time Recurrent Neural Networks (CTRNNs)** due to their ability to accurately model the continuous and dynamic nature of biological neural processes. CTRNNs can mimic the temporal dynamics and adaptive learning capabilities of biological neural networks, providing a closer approximation to real neurological processes. Furthermore, their robustness in handling noisy environments, capability to generate complex behaviors, and applicability in studying real-time interactions and sensorimotor coordination make them a valuable tool in neuroscience research and experimentation.\n",
        "\n",
        "Let us define a continuous-time neural network,\n",
        "\\begin{align}\n",
        "    \\tau \\frac{d\\mathbf{r}}{dt} = -\\mathbf{r}(t) + f(W_r \\mathbf{r}(t) + W_x \\mathbf{x}(t) + \\mathbf{b}_r).\n",
        "\\end{align}\n",
        "\n",
        "Where,\n",
        "\n",
        "$r(t)$ is the vector of neural firing rates (or activations) at time $t$.\n",
        "\n",
        "$τ$ is the time constant which determines how fast the state approaches its steady-state value.\n",
        "\n",
        "$f$ is a non-linear activation function applied element-wise.\n",
        "\n",
        "$W_r$ is the recurrent weight matrix.\n",
        "\n",
        "$x(t)$ is the input vector at time $t$.\n",
        "\n",
        "$W_x$ is the input weight matrix.\n",
        "\n",
        "$b_r​$ is the bias vector.\n",
        "\n",
        "\n",
        "Let us discretize this network in time using the Euler method with a time step of $\\Delta t$,\n",
        "\\begin{align}\n",
        "    \\mathbf{r}(t+\\Delta t) = \\mathbf{r}(t) + \\Delta \\mathbf{r} &= \\mathbf{r}(t) + \\frac{\\Delta t}{\\tau}[-\\mathbf{r}(t) + f(W_r \\mathbf{r}(t) + W_x \\mathbf{x}(t) + \\mathbf{b}_r)] \\\\\n",
        "    &= (1 - \\frac{\\Delta t}{\\tau})\\mathbf{r}(t) + \\frac{\\Delta t}{\\tau}f(W_r \\mathbf{r}(t) + W_x \\mathbf{x}(t) + \\mathbf{b}_r)\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now define the network following the dynamics described by the above equation."
      ],
      "metadata": {
        "id": "friRVLXaMegj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coupled-sessions"
      },
      "outputs": [],
      "source": [
        "class CTRNN(nn.Module):\n",
        "    \"\"\"Continuous-time RNN.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: Number of input neurons\n",
        "        hidden_size: Number of hidden neurons\n",
        "        dt: discretization time step in ms.\n",
        "            If None, dt equals time constant tau\n",
        "\n",
        "    Inputs:\n",
        "        input: tensor of shape (seq_len, batch, input_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), initial hidden activity\n",
        "            if None, hidden is initialized through self.init_hidden()\n",
        "\n",
        "    Outputs:\n",
        "        output: tensor of shape (seq_len, batch, hidden_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), final hidden activity\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, dt=None, **kwargs):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tau = 100\n",
        "        if dt is None:\n",
        "            alpha = 1\n",
        "        else:\n",
        "            alpha = 'TODO'\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.input2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def init_hidden(self, input_shape):\n",
        "        batch_size = 'TODO'\n",
        "        return torch.zeros(batch_size, self.hidden_size)\n",
        "\n",
        "    def recurrence(self, input, hidden):\n",
        "        \"\"\"Run network for one time step.\n",
        "\n",
        "        Inputs:\n",
        "            input: tensor of shape (batch, input_size)\n",
        "            hidden: tensor of shape (batch, hidden_size)\n",
        "\n",
        "        Outputs:\n",
        "            h_new: tensor of shape (batch, hidden_size),\n",
        "                network activity at the next time step\n",
        "        \"\"\"\n",
        "        h_new = torch.relu(self.input2h(input) + self.h2h(hidden))\n",
        "        h_new = 'TODO'\n",
        "        return h_new\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        \"\"\"Propagate input through the network.\"\"\"\n",
        "\n",
        "        # If hidden activity is not provided, initialize it\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input.shape).to(input.device)\n",
        "\n",
        "        # Loop through time\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden)\n",
        "\n",
        "        # Stack together output from all time steps\n",
        "        output = 'TODO' # (seq_len, batch, hidden_size)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "class RNNNet(nn.Module):\n",
        "    \"\"\"Recurrent network model.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: int, input size\n",
        "        hidden_size: int, hidden size\n",
        "        output_size: int, output size\n",
        "\n",
        "    Inputs:\n",
        "        x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "    Outputs:\n",
        "        out: tensor of shape (Seq Len, Batch, Output size)\n",
        "        rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        # Continuous time RNN\n",
        "        self.rnn = CTRNN(input_size, hidden_size, **kwargs)\n",
        "\n",
        "        # Add an output layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_output, _ = self.rnn(x)\n",
        "        out = self.fc(rnn_output)\n",
        "        return out, rnn_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's determine the dimensions of its inputs and outputs."
      ],
      "metadata": {
        "id": "zscQyqJKAPsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "seq_len = 20  # sequence length\n",
        "input_size = 5  # input dimension\n",
        "\n",
        "# Make some random inputs\n",
        "input_rnn = torch.rand(seq_len, batch_size, input_size)\n",
        "\n",
        "# Make network of 100 hidden units and 10 output units\n",
        "rnn = RNNNet(input_size= 'TODO')\n",
        "\n",
        "# Run the sequence through the network\n",
        "out, rnn_output = 'TODO'\n",
        "\n",
        "print('Input of shape =', input_rnn.shape)\n",
        "print('Output of shape =', out.shape)"
      ],
      "metadata": {
        "id": "cJiMYOS0A4QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "artificial-michael"
      },
      "source": [
        "## Defining a simple cognitive task"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we use the neurogym package to make a simple \"perceptual decision making\" task. Let us install the package first.NeuroGym is a curated collection of neuroscience tasks with a common interface. You may explore further [here](https://github.com/neurogym/neurogym)\n",
        "\n",
        "The code provided below defines a custom environment, PerceptualDecisionMaking, using neurogym. This environment simulates a two-alternative forced choice task where an agent needs to decide which of two stimuli is higher on average, despite the stimuli being noisy. The agent is encouraged to integrate the stimulus over time due to this noise.\n",
        "\n",
        "Given that the focus of today's tutorial is on training an RNN, feel free to navigate through this section, which involves defining a cognitive task, at your own pace."
      ],
      "metadata": {
        "id": "Aq0JWZh1JCFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Installing neurogym\n",
        "! git clone https://github.com/neurogym/neurogym.git\n",
        "%cd neurogym/\n",
        "! pip install -e ."
      ],
      "metadata": {
        "id": "XqDGBDN1Sc3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3KQN9OCB_c8"
      },
      "outputs": [],
      "source": [
        "# @title importing neurogym\n",
        "import gym  # package for RL environments\n",
        "import neurogym as ngym\n",
        "\n",
        "# Canned environment from neurogym\n",
        "task_name = 'PerceptualDecisionMaking-v0'\n",
        "# Importantly, we set discretization time step for the task as well\n",
        "kwargs = {'dt': 20, 'timing': {'stimulus': 1000}}\n",
        "\n",
        "# Boilerplate gym\n",
        "env = gym.make(task_name, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9RRJrrhB_c9"
      },
      "outputs": [],
      "source": [
        "# @title Defining the perceptual decision making task\n",
        "\n",
        "from neurogym import spaces\n",
        "\n",
        "class PerceptualDecisionMaking(ngym.TrialEnv):\n",
        "    \"\"\"Two-alternative forced choice task in which the subject has to\n",
        "    integrate two stimuli to decide which one is higher on average.\n",
        "    A noisy stimulus is shown during the stimulus period. The strength (\n",
        "    coherence) of the stimulus is randomly sampled every trial. Because the\n",
        "    stimulus is noisy, the agent is encouraged to integrate the stimulus\n",
        "    over time.\n",
        "    Args:\n",
        "        cohs: list of float, coherence levels controlling the difficulty of\n",
        "            the task\n",
        "        sigma: float, input noise level\n",
        "        dim_ring: int, dimension of ring input and output\n",
        "    \"\"\"\n",
        "    metadata = {\n",
        "        'paper_link': 'https://www.jneurosci.org/content/12/12/4745',\n",
        "        'paper_name': '''The analysis of visual motion: a comparison of\n",
        "        neuronal and psychophysical performance''',\n",
        "        'tags': ['perceptual', 'two-alternative', 'supervised']\n",
        "    }\n",
        "\n",
        "    def __init__(self, dt=100, rewards=None, timing=None, cohs=None,\n",
        "                 sigma=1.0, dim_ring=2):\n",
        "        super().__init__(dt=dt)\n",
        "        if cohs is None:\n",
        "            self.cohs = np.array([0, 6.4, 12.8, 25.6, 51.2])\n",
        "        else:\n",
        "            self.cohs = cohs\n",
        "        self.sigma = sigma / np.sqrt(self.dt)  # Input noise\n",
        "\n",
        "        # Rewards\n",
        "        self.rewards = {'abort': -0.1, 'correct': +1., 'fail': 0.}\n",
        "        if rewards:\n",
        "            self.rewards.update(rewards)\n",
        "\n",
        "        self.timing = {\n",
        "            'fixation': 100,\n",
        "            'stimulus': 2000,\n",
        "            'delay': 0,\n",
        "            'decision': 100}\n",
        "        if timing:\n",
        "            self.timing.update(timing)\n",
        "\n",
        "        self.abort = False\n",
        "\n",
        "        self.theta = np.linspace(0, 2*np.pi, dim_ring+1)[:-1]\n",
        "        self.choices = np.arange(dim_ring)\n",
        "\n",
        "        name = {'fixation': 0, 'stimulus': range(1, dim_ring+1)}\n",
        "        self.observation_space = spaces.Box(\n",
        "            -np.inf, np.inf, shape=(1+dim_ring,), dtype=np.float32, name=name)\n",
        "        name = {'fixation': 0, 'choice': range(1, dim_ring+1)}\n",
        "        self.action_space = spaces.Discrete(1+dim_ring, name=name)\n",
        "\n",
        "    def _new_trial(self, **kwargs):\n",
        "        \"\"\"\n",
        "        new_trial() is called when a trial ends to generate the next trial.\n",
        "        The following variables are created:\n",
        "            durations, which stores the duration of the different periods (in\n",
        "            the case of perceptualDecisionMaking: fixation, stimulus and\n",
        "            decision periods)\n",
        "            ground truth: correct response for the trial\n",
        "            coh: stimulus coherence (evidence) for the trial\n",
        "            obs: observation\n",
        "        \"\"\"\n",
        "        # Trial info\n",
        "        trial = {\n",
        "            'ground_truth': self.rng.choice(self.choices),\n",
        "            'coh': self.rng.choice(self.cohs),\n",
        "        }\n",
        "        trial.update(kwargs)\n",
        "\n",
        "        coh = trial['coh']\n",
        "        ground_truth = trial['ground_truth']\n",
        "        stim_theta = self.theta[ground_truth]\n",
        "\n",
        "        # Periods\n",
        "        self.add_period(['fixation', 'stimulus', 'delay', 'decision'])\n",
        "\n",
        "        # Observations\n",
        "        self.add_ob(1, period=['fixation', 'stimulus', 'delay'], where='fixation')\n",
        "        stim = np.cos(self.theta - stim_theta) * (coh/200) + 0.5\n",
        "        self.add_ob(stim, 'stimulus', where='stimulus')\n",
        "        self.add_randn(0, self.sigma, 'stimulus', where='stimulus')\n",
        "\n",
        "        # Ground truth\n",
        "        self.set_groundtruth(ground_truth, period='decision', where='choice')\n",
        "\n",
        "        return trial\n",
        "\n",
        "    def _step(self, action):\n",
        "        \"\"\"\n",
        "        _step receives an action and returns:\n",
        "            a new observation, obs\n",
        "            reward associated with the action, reward\n",
        "            a boolean variable indicating whether the experiment has end, done\n",
        "            a dictionary with extra information:\n",
        "                ground truth correct response, info['gt']\n",
        "                boolean indicating the end of the trial, info['new_trial']\n",
        "        \"\"\"\n",
        "        new_trial = False\n",
        "        # rewards\n",
        "        reward = 0\n",
        "        gt = self.gt_now\n",
        "        # observations\n",
        "        if self.in_period('fixation'):\n",
        "            if action != 0:  # action = 0 means fixating\n",
        "                new_trial = self.abort\n",
        "                reward += self.rewards['abort']\n",
        "        elif self.in_period('decision'):\n",
        "            if action != 0:\n",
        "                new_trial = True\n",
        "                if action == gt:\n",
        "                    reward += self.rewards['correct']\n",
        "                    self.performance = 1\n",
        "                else:\n",
        "                    reward += self.rewards['fail']\n",
        "\n",
        "        return self.ob_now, reward, False, {'new_trial': new_trial, 'gt': gt}\n",
        "\n",
        "# Create environment from source code\n",
        "env2 = PerceptualDecisionMaking(**kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHgkiXmEB_c9"
      },
      "source": [
        "**Visualize the environment.**\n",
        "\n",
        "The following function helps us visualize the environment. It shows from top\n",
        "1. Observation that the network/agent receives,\n",
        "2. Actions taken by a random agent and the ground-truth (when applicable),\n",
        "3. Reward received by the agent (relevant for reinforcement learning),\n",
        "4. Performance of the network (we'll re-compute this explicitly ourselves)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9LbgcvhB_c9"
      },
      "outputs": [],
      "source": [
        "# @title Visualize the environment with 2 sample trials\n",
        "\n",
        "import logging\n",
        "logging.getLogger(\"matplotlib\").setLevel(logging.CRITICAL)\n",
        "\n",
        "_ = ngym.utils.plot_env(env, num_trials=2)\n",
        "\n",
        "# This is a simple task, the input and output are low-dimensional\n",
        "input_size = env.observation_space.shape[0]\n",
        "output_size = env.action_space.n\n",
        "print('Input size', input_size)\n",
        "print('Output size', output_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yro2ByHB_c9"
      },
      "source": [
        "For **supervised learning**, we need a dataset that returns (input, target output pairs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa-AtjsVB_c9"
      },
      "outputs": [],
      "source": [
        "# Make supervised dataset, neurogym boilerplate\n",
        "seq_len = 100\n",
        "batch_size = 16\n",
        "dataset = ngym.Dataset(env, batch_size=batch_size, seq_len=seq_len)\n",
        "\n",
        "# Generate one batch of data when called\n",
        "inputs, target = dataset()\n",
        "print('Input has shape (SeqLen, Batch, Dim) =', inputs.shape)\n",
        "print('Target has shape (SeqLen, Batch) =', target.shape)\n",
        "print('Target are the integers, for example target in the first sequence:')\n",
        "print(target[:, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "separate-message"
      },
      "source": [
        "## Network Training\n",
        "\n",
        "Let's now train the network to perform the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "romantic-recognition"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "# Instantiate the network and print information\n",
        "hidden_size = 128\n",
        "net = RNNNet(input_size=input_size, hidden_size=hidden_size,\n",
        "             output_size=output_size, dt=env.dt)\n",
        "print(net)\n",
        "\n",
        "def train_model(net, dataset):\n",
        "    \"\"\"Simple helper function to train the model.\n",
        "\n",
        "    Args:\n",
        "        net: a pytorch nn.Module module\n",
        "        dataset: a dataset object that when called produce a (input, target output) pair\n",
        "\n",
        "    Returns:\n",
        "        net: network object after training\n",
        "    \"\"\"\n",
        "    # Use Adam optimizer\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    start_time = time.time()\n",
        "    # Loop over training batches\n",
        "    print('Training network...')\n",
        "    for i in range(1000):\n",
        "        # Generate input and target, convert to pytorch tensor\n",
        "        inputs, labels = dataset()\n",
        "        inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "        labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
        "\n",
        "        # boiler plate pytorch training:\n",
        "        optimizer.zero_grad()   # zero the gradient buffers\n",
        "        output, _ = net(inputs)\n",
        "        # Reshape to (SeqLen x Batch, OutputSize)\n",
        "        output = output.view(-1, output_size)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()    # Does the update\n",
        "\n",
        "        # Compute the running loss every 100 steps\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            running_loss /= 100\n",
        "            print('Step {}, Loss {:0.4f}, Time {:0.1f}s'.format(\n",
        "                i+1, running_loss, time.time() - start_time))\n",
        "            running_loss = 0\n",
        "    return net\n",
        "\n",
        "net = 'TODO'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "affected-divide"
      },
      "source": [
        "## Testing the network\n",
        "\n",
        "\n",
        "Here we run the network after training, record activity, and compute performance. We will explicitly loop through individual trials, so we can log the information and compute the performance of each trial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yellow-jason"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Reset environment\n",
        "env = dataset.env\n",
        "env.reset(no_step=True)\n",
        "\n",
        "# Initialize variables for logging\n",
        "perf = 0\n",
        "activity_dict = {}  # recording activity\n",
        "trial_infos = {}  # recording trial information\n",
        "\n",
        "num_trial = 200\n",
        "for i in range(num_trial):\n",
        "    # Neurogym boiler plate\n",
        "    # Sample a new trial\n",
        "    trial_info = env.new_trial()\n",
        "    # Observation and groud-truth of this trial\n",
        "    ob, gt = env.ob, env.gt\n",
        "    # Convert to numpy, add batch dimension to input\n",
        "    inputs = torch.from_numpy(ob[:, np.newaxis, :]).type(torch.float)\n",
        "\n",
        "    # Run the network for one trial\n",
        "    # inputs (SeqLen, Batch, InputSize)\n",
        "    # action_pred (SeqLen, Batch, OutputSize)\n",
        "    action_pred, rnn_activity = net(inputs)\n",
        "\n",
        "    # Compute performance\n",
        "    # First convert back to numpy\n",
        "    action_pred = action_pred.detach().numpy()[:, 0, :]\n",
        "    # Read out final choice at last time step\n",
        "    choice = np.argmax(action_pred[-1, :])\n",
        "    # Compare to ground truth\n",
        "    correct = choice == gt[-1]\n",
        "\n",
        "    # Record activity, trial information, choice, correctness\n",
        "    rnn_activity = rnn_activity[:, 0, :].detach().numpy()\n",
        "    activity_dict[i] = rnn_activity\n",
        "    trial_infos[i] = trial_info  # trial_info is a dictionary\n",
        "    trial_infos[i].update({'correct': correct})\n",
        "\n",
        "# Print information for sample trials\n",
        "for i in range(5):\n",
        "    print('Trial ', i, trial_infos[i])\n",
        "\n",
        "print('Average performance', np.mean([val['correct'] for val in trial_infos.values()]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises"
      ],
      "metadata": {
        "id": "AwZKSWVC86bL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suffering-persian"
      },
      "source": [
        "### Exercise 1: Plot the network's activity in PCA\n",
        "\n",
        "Next we will analyze the network by plotting its activity in PCA space. Each trajectory in the PC-space would correspond to a single trial.\n",
        "\n",
        "**Principal Components Analysis (PCA)** is a dimensionality reduction technique that is commonly used in neuroscience to understand the major patterns of activity across many neurons. PCA works by by linearly transforming the data into a new coordinate system where (most of) the variation in the data can be described with fewer dimensions than the initial data. When transforming the data to 2 or 3 dimensions, we can visualise data that was originally too complex to understand, do to the large amount of neurons. Just like with real neurons, we can perform PCA on our artificial neurons, and see the underlying patterns of activity in the network.\n",
        "\n",
        "For further reading: [Link](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "distinct-diploma"
      },
      "outputs": [],
      "source": [
        "# Apply PCA, boilerplate sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Concatenate activity for PCA\n",
        "activity = np.concatenate(list(activity_dict[i] for i in range(num_trial)), axis=0)\n",
        "print('Shape of the neural activity: (Time points, Neurons): ', activity.shape)\n",
        "\n",
        "pca =  'TODO' # Perform PCA and keep 2 components\n",
        "pca.fit(activity)  # activity (Time points, Neurons)\n",
        "activity_pc = 'TODO' # transform to low-dimension\n",
        "print('Shape of the projected activity: (Time points, PCs): ', activity_pc.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sapphire-alabama"
      },
      "outputs": [],
      "source": [
        "# Project each trial and visualize activity\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "logging.getLogger(\"matplotlib\").setLevel(logging.CRITICAL)\n",
        "\n",
        "\n",
        "# Plot all trials in ax1, plot fewer trials in ax2\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex=True, figsize=(6, 3))\n",
        "\n",
        "for i in range(100):\n",
        "    # Transform and plot each trial\n",
        "    activity_pc = pca.transform(activity_dict[i])  # (Time points, PCs)\n",
        "\n",
        "    trial = trial_infos[i]\n",
        "    color = 'red' if trial['ground_truth'] == 0 else 'blue'\n",
        "\n",
        "    _ = ax1.plot(activity_pc[:, 0], activity_pc[:, 1], 'o-', color=color)\n",
        "    if i < 3:\n",
        "        _ = ax2.plot(activity_pc[:,\n",
        "                                 0], activity_pc[:, 1], 'o-', color=color)\n",
        "\n",
        "    # Plot the beginning of a trial with a special symbol\n",
        "    _ = ax1.plot(activity_pc[0, 0], activity_pc[0, 1], '^', color='black')\n",
        "\n",
        "ax1.set_title('{:d} Trials'.format(100))\n",
        "ax2.set_title('{:d} Trials'.format(3))\n",
        "ax1.set_xlabel('PC 1')\n",
        "ax1.set_ylabel('PC 2')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2: Model Assessment\n",
        "\n",
        "Write a function to assess the performance of our model. Calculate the average performance of the model over all tested trials and print it out, in order to provide a quick summary of how well the model performed.\n",
        "\n"
      ],
      "metadata": {
        "id": "xjSjtlGHLVRG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OpZioSzzVUqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "continuing-planning"
      },
      "source": [
        "### Exercise 3: Adjusting Time Variables\n",
        "\n",
        "Change the time constant of network units from 100ms to 40ms, and re-train the network. How does the final performance change?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-TYda6F0pWj"
      },
      "source": [
        "kwargs = {'dt': 20, 'timing': {'stimulus': 1000}}\n",
        "\n",
        "# Boilerplate gym\n",
        "env = gym.make(task_name, **kwargs)\n",
        "dataset = ngym.Dataset(env, batch_size=batch_size, seq_len=seq_len)\n",
        "# Generate one batch of data when called\n",
        "inputs, target = dataset()\n",
        "input_size = env.observation_space.shape[0]\n",
        "output_size = env.action_space.n\n",
        "\n",
        "net = RNNNet('TODO')\n",
        "# print(net)\n",
        "\n",
        "trial_infos, activity_dict = 'TODO'\n",
        "print('Average performance pre-training', np.mean([val['correct'] for val in trial_infos.values()]))\n",
        "\n",
        "net = train_model(net, dataset)\n",
        "\n",
        "trial_infos, activity_dict = 'TODO'\n",
        "print('Average performance post-training', np.mean([val['correct'] for val in trial_infos.values()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4: Implementing a Multi-layer RNN\n",
        "\n",
        "Create a Multi-layer Recurrent Neural Network (MultiRNN) that has multiple layers of RNNs stacked on top of each other. Analyze its performance in comparison to the single-layer RNN provided."
      ],
      "metadata": {
        "id": "bIJVpMOXyMiW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hC5rd-Ab1zKm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}